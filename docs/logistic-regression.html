<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Logistic Regression | Multiple and Logistic Regression</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Logistic Regression | Multiple and Logistic Regression" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Logistic Regression | Multiple and Logistic Regression" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Your Name Here" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multiple-regression.html"/>
<link rel="next" href="case-study-italian-restaurant-in-nyc.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.46.1/plotly-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="parallel-slopes.html"><a href="parallel-slopes.html"><i class="fa fa-check"></i><b>2</b> Parallel Slopes</a><ul>
<li class="chapter" data-level="2.1" data-path="parallel-slopes.html"><a href="parallel-slopes.html#fitting-a-parallel-slopes-model"><i class="fa fa-check"></i><b>2.1</b> Fitting a parallel slopes model</a><ul>
<li class="chapter" data-level="" data-path="parallel-slopes.html"><a href="parallel-slopes.html#exercise"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="" data-path="parallel-slopes.html"><a href="parallel-slopes.html#reasoning-about-two-intercepts"><i class="fa fa-check"></i>Reasoning about two intercepts</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="parallel-slopes.html"><a href="parallel-slopes.html#using-geom_line-and-augment"><i class="fa fa-check"></i><b>2.2</b> Using <code>geom_line()</code> and <code>augment()</code></a><ul>
<li class="chapter" data-level="" data-path="parallel-slopes.html"><a href="parallel-slopes.html#exercise-1"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="" data-path="parallel-slopes.html"><a href="parallel-slopes.html#intercept-interpretation"><i class="fa fa-check"></i>Intercept interpretation</a></li>
<li class="chapter" data-level="" data-path="parallel-slopes.html"><a href="parallel-slopes.html#common-slope-interpretation"><i class="fa fa-check"></i>Common slope interpretation</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="parallel-slopes.html"><a href="parallel-slopes.html#syntax-from-math"><i class="fa fa-check"></i><b>2.3</b> Syntax from math</a><ul>
<li class="chapter" data-level="" data-path="parallel-slopes.html"><a href="parallel-slopes.html#exercise-2"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="parallel-slopes.html"><a href="parallel-slopes.html#syntax-from-plot"><i class="fa fa-check"></i><b>2.4</b> Syntax from plot</a><ul>
<li class="chapter" data-level="" data-path="parallel-slopes.html"><a href="parallel-slopes.html#exercise-3"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html"><i class="fa fa-check"></i><b>3</b> Evaluating and extending parallel slopes model</a><ul>
<li class="chapter" data-level="3.1" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html#r-squared-vs.adjusted-r-squared"><i class="fa fa-check"></i><b>3.1</b> R-squared vs.Â adjusted R-squared</a><ul>
<li class="chapter" data-level="" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html#exercise-4"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html#prediction"><i class="fa fa-check"></i><b>3.2</b> Prediction</a><ul>
<li class="chapter" data-level="" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html#exercise-5"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html#thought-experiments"><i class="fa fa-check"></i>Thought experiments</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html#fitting-a-model-with-interaction"><i class="fa fa-check"></i><b>3.3</b> Fitting a model with interaction</a><ul>
<li class="chapter" data-level="" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html#exercise-6"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html#visualizing-interaction-models"><i class="fa fa-check"></i><b>3.4</b> Visualizing interaction models</a></li>
<li class="chapter" data-level="" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html#exercise-7"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="3.5" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html#consequences-of-simpsons-paradox"><i class="fa fa-check"></i><b>3.5</b> Consequences of Simpsonâs paradox</a></li>
<li class="chapter" data-level="3.6" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html#simpsons-paradox-in-action"><i class="fa fa-check"></i><b>3.6</b> Simpsonâs paradox in action</a><ul>
<li class="chapter" data-level="" data-path="evaluating-and-extending-parallel-slopes-model.html"><a href="evaluating-and-extending-parallel-slopes-model.html#exercise-8"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>4</b> Multiple Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="multiple-regression.html"><a href="multiple-regression.html#fitting-a-mlr-model"><i class="fa fa-check"></i><b>4.1</b> Fitting a MLR model</a></li>
<li class="chapter" data-level="4.2" data-path="multiple-regression.html"><a href="multiple-regression.html#tiling-the-plane"><i class="fa fa-check"></i><b>4.2</b> Tiling the plane</a><ul>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#exercise-9"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="multiple-regression.html"><a href="multiple-regression.html#models-in-3d"><i class="fa fa-check"></i><b>4.3</b> Models in 3D</a><ul>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#exercise-10"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#coefficient-magnitude"><i class="fa fa-check"></i>Coefficient magnitude</a></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#practicing-interpretation"><i class="fa fa-check"></i>Practicing interpretation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="multiple-regression.html"><a href="multiple-regression.html#visualizing-parallel-planes"><i class="fa fa-check"></i><b>4.4</b> Visualizing parallel planes</a><ul>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#exercise-11"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#parallel-plane-interpretation"><i class="fa fa-check"></i>Parallel plane interpretation</a></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#interpretation-of-coefficient-in-a-big-model"><i class="fa fa-check"></i>Interpretation of coefficient in a big model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>5</b> Logistic Regression</a><ul>
<li class="chapter" data-level="5.1" data-path="logistic-regression.html"><a href="logistic-regression.html#fitting-a-line-to-a-binary-response"><i class="fa fa-check"></i><b>5.1</b> Fitting a line to a binary response</a><ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-12"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="logistic-regression.html"><a href="logistic-regression.html#fitting-a-line-to-a-binary-response-2"><i class="fa fa-check"></i><b>5.2</b> Fitting a line to a binary response (2)</a><ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-13"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="logistic-regression.html"><a href="logistic-regression.html#fitting-a-model"><i class="fa fa-check"></i><b>5.3</b> Fitting a model</a><ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-14"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="logistic-regression.html"><a href="logistic-regression.html#using-geom_smooth"><i class="fa fa-check"></i><b>5.4</b> Using geom_smooth()</a><ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-15"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="logistic-regression.html"><a href="logistic-regression.html#using-bins"><i class="fa fa-check"></i><b>5.5</b> Using bins</a><ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-16"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="logistic-regression.html"><a href="logistic-regression.html#odds-scale"><i class="fa fa-check"></i><b>5.6</b> Odds scale</a><ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-17"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="logistic-regression.html"><a href="logistic-regression.html#log-odds-scale"><i class="fa fa-check"></i><b>5.7</b> Log-odds scale</a><ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-18"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#interpretation-of-logistic-regression"><i class="fa fa-check"></i>Interpretation of logistic regression</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="logistic-regression.html"><a href="logistic-regression.html#making-probabilistic-predictions"><i class="fa fa-check"></i><b>5.8</b> Making probabilistic predictions</a><ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-19"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="logistic-regression.html"><a href="logistic-regression.html#making-binary-predictions"><i class="fa fa-check"></i><b>5.9</b> Making binary predictions</a><ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-20"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html"><i class="fa fa-check"></i><b>6</b> Case Study: Italian restaurant in NYC</a><ul>
<li class="chapter" data-level="" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#exploratory-data-analysis"><i class="fa fa-check"></i>Exploratory data analysis</a></li>
<li class="chapter" data-level="" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#excercise"><i class="fa fa-check"></i>Excercise</a></li>
<li class="chapter" data-level="6.1" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#slr-models"><i class="fa fa-check"></i><b>6.1</b> SLR models</a><ul>
<li class="chapter" data-level="" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#exercise-21"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#parallel-lines-with-location"><i class="fa fa-check"></i><b>6.2</b> Parallel lines with location</a></li>
<li class="chapter" data-level="6.3" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#a-plane-in-3d"><i class="fa fa-check"></i><b>6.3</b> A plane in 3D</a><ul>
<li class="chapter" data-level="" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#exercise-22"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#parallel-planes-with-location"><i class="fa fa-check"></i><b>6.4</b> Parallel planes with location</a><ul>
<li class="chapter" data-level="" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#exercise-23"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#interpretation-of-location-coefficient"><i class="fa fa-check"></i>Interpretation of location coefficient</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#impact-of-location"><i class="fa fa-check"></i><b>6.5</b> Impact of location</a><ul>
<li class="chapter" data-level="" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#exercise-24"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="case-study-italian-restaurant-in-nyc.html"><a href="case-study-italian-restaurant-in-nyc.html#full-model"><i class="fa fa-check"></i><b>6.6</b> Full model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><a href="https://www.datacamp.com/courses/multiple-and-logistic-regression">Multiple and Logistic Regression</a></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Logistic Regression</h1>
<p>n this chapter youâll learn about using logistic regression, a generalized linear model (GLM), to predict a binary outcome and classify observations.</p>
<hr />
<div id="fitting-a-line-to-a-binary-response" class="section level2">
<h2><span class="header-section-number">5.1</span> Fitting a line to a binary response</h2>
<p>When our response variable is binary, a regression model has several limitations. Among the more obviousâand logically incongruousâis that the regression line extends infinitely in either direction. This means that even though our response variable <span class="math inline">\(y\)</span> only takes on the values 0 and 1, our fitted values <span class="math inline">\(\hat{y}\)</span> can range anywhere from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>. This doesnât make sense.</p>
<p>To see this in action, weâll fit a linear regression model to data about 55 students who applied to medical school. We want to understand how their undergraduate GPA relates to the probability they will be accepted by a particular school (<code>Acceptance</code>).</p>
<hr />
<div id="exercise-12" class="section level3 unnumbered">
<h3>Exercise</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(Stat2Data)
<span class="kw">data</span>(MedGPA)</code></pre></div>
<p>The medical school acceptance data is loaded in your workspace as <code>MedGPA</code>.</p>
<ul>
<li>Create a scatterplot called <code>data_space</code> for <code>Acceptance</code> as a function of <code>GPA</code>. Use <code>geom_jitter()</code> to apply a small amount of jitter to the points in the y-direction by setting <code>width = 0</code> and <code>height = 0.05</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># scatterplot with jitter</span>
data_space &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> MedGPA, <span class="kw">aes</span>(<span class="dt">x =</span> GPA, <span class="dt">y =</span> Acceptance)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="dv">0</span>, <span class="dt">height =</span> <span class="fl">0.05</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()
data_space</code></pre></div>
<p><img src="MultLogSC_files/figure-html/unnamed-chunk-41-1.png" width="384" style="display: block; margin: auto;" /></p>
<ul>
<li>Use <code>geom_smooth()</code> to add the simple linear regression line to <code>data_space</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># linear regression line</span>
data_space <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p><img src="MultLogSC_files/figure-html/unnamed-chunk-42-1.png" width="384" style="display: block; margin: auto;" /></p>
<hr />
</div>
</div>
<div id="fitting-a-line-to-a-binary-response-2" class="section level2">
<h2><span class="header-section-number">5.2</span> Fitting a line to a binary response (2)</h2>
<p>In the previous exercise, we identified a major limitation to fitting a linear regression model when we have a binary response variable. However, it is not always inappropriate to do so. Note that our regression line only makes illogical predictions (i.e. <span class="math inline">\(\hat{y} &lt; 0\)</span> or <span class="math inline">\(\hat{y} &gt; 1\)</span>) for students with very high or very low GPAs. For GPAs closer to average, the predictions seem fine.</p>
<p>Moreover, the alternative logistic regression modelâwhich we will fit nextâis very similar to the linear regression model for observations near the average of the explanatory variable. It just so happens that the logistic curve is very straight near its middle. Thus, in these cases a linear regression model may still be acceptable, even for a binary response.</p>
<hr />
<div id="exercise-13" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Use <code>filter()</code> to find the subset of the observations whose GPAs are between 3.375 and 3.77, inclusive.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># filter</span>
MedGPA_middle &lt;-<span class="st"> </span><span class="kw">filter</span>(MedGPA, GPA <span class="op">&gt;=</span><span class="st"> </span><span class="fl">3.375</span>, GPA <span class="op">&lt;=</span><span class="st"> </span><span class="fl">3.77</span>)
<span class="kw">head</span>(MedGPA_middle)</code></pre></div>
<pre><code>  Accept Acceptance Sex BCPM  GPA VR PS WS BS MCAT Apps
1      D          0   F 3.59 3.62 11  9  9  9   38    5
2      A          1   F 3.74 3.69 12 11  7 10   40    5
3      A          1   F 3.53 3.38  9 11  4 11   35   11
4      A          1   M 3.59 3.72 10  9  7 10   36    5
5      A          1   F 3.74 3.71  8 10  6 11   35    5
6      A          1   F 3.35 3.49 11  8  4  8   31    9</code></pre>
<ul>
<li>Create a scatterplot called data_space for Acceptance as a function of GPA for only those observations. Use geom_jitter() to apply 0.05 jitter to the points in the <span class="math inline">\(y\)</span>-direction and no jitter to the <span class="math inline">\(x\)</span>-direction.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># scatterplot with jitter</span>
data_space &lt;-<span class="st"> </span><span class="kw">ggplot</span>(MedGPA_middle, <span class="kw">aes</span>(<span class="dt">x =</span> GPA, <span class="dt">y =</span> Acceptance)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="dv">0</span>, <span class="dt">height =</span> <span class="fl">0.05</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()
data_space</code></pre></div>
<p><img src="MultLogSC_files/figure-html/unnamed-chunk-44-1.png" width="384" style="display: block; margin: auto;" /></p>
<ul>
<li>Use geom_smooth() to add only the simple linear regression line to data_space.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># linear regression line</span>
data_space <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p><img src="MultLogSC_files/figure-html/unnamed-chunk-45-1.png" width="384" style="display: block; margin: auto;" /></p>
<hr />
</div>
</div>
<div id="fitting-a-model" class="section level2">
<h2><span class="header-section-number">5.3</span> Fitting a model</h2>
<p>Logistic regression is a special case of a broader class of <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">generalized linear models</a>, often known as GLMs. Specifying a logistic regression model is very similar to specify a regression model, with two important differences:</p>
<ul>
<li><p>We use the <code>glm()</code> function instead of <code>lm()</code></p></li>
<li><p>We specify the <code>family</code> argument and set it to <code>binomial</code>. This tells the GLM function that we want to fit a logistic regression model to our binary response. <a href="https://en.wikipedia.org/wiki/Binomial_distribution">The terminology stems from the assumption that our binary response follows a {binomial distribution.</a></p></li>
</ul>
<p>We still use the formula and data arguments with <code>glm()</code>.</p>
Note that the mathematical model is now:
<span class="math display">\[\begin{equation}
\log\left(\frac{y}{1-y}\right) = \beta_0 + \beta_1 \cdot x + \varepsilon,
\end{equation}\]</span>
<p>where <span class="math inline">\(\varepsilon\)</span> is the error term.</p>
<hr />
<div id="exercise-14" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Use <code>glm()</code> to fit a logistic regression model for <code>Acceptance</code> as a function of <code>GPA</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit model</span>
mod &lt;-<span class="st"> </span><span class="kw">glm</span>(Acceptance <span class="op">~</span><span class="st"> </span>GPA, <span class="dt">data =</span> MedGPA, <span class="dt">family =</span> binomial)
mod</code></pre></div>
<pre><code>
Call:  glm(formula = Acceptance ~ GPA, family = binomial, data = MedGPA)

Coefficients:
(Intercept)          GPA  
    -19.207        5.454  

Degrees of Freedom: 54 Total (i.e. Null);  53 Residual
Null Deviance:      75.79 
Residual Deviance: 56.84    AIC: 60.84</code></pre>
<hr />
</div>
</div>
<div id="using-geom_smooth" class="section level2">
<h2><span class="header-section-number">5.4</span> Using geom_smooth()</h2>
<p>Our logistic regression model can be visualized in the data space by overlaying the appropriate logistic curve. We can use the <code>geom_smooth()</code> function to do this. Recall that <code>geom_smooth()</code> takes a method argument that allows you to specify what type of smoother you want to see. In our case, we need to specify that we want to use the <code>glm()</code> function to do the smoothing.</p>
<p>However we also need to tell the <code>glm()</code> function which member of the GLM family we want to use. To do this, we will pass the <code>family</code> argument to <code>glm()</code> as a list using the <code>method.args</code> argument to <code>geom_smooth()</code>. This mechanism is common in R, and allows one function to pass a list of arguments to another function.</p>
<hr />
<div id="exercise-15" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Create a scatterplot called <code>data_space</code> for <code>Acceptance</code> as a function of <code>GPA</code>. Use <code>geom_jitter()</code> to apply a small amount of jitter to the points in the <span class="math inline">\(y\)</span>-direction. Set <code>width = 0</code> and <code>height = 0.05</code> in <code>geom_jitter()</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># scatterplot with jitter</span>
data_space &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> MedGPA, <span class="kw">aes</span>(<span class="dt">y =</span> Acceptance, <span class="dt">x =</span> GPA)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="dv">0</span>, <span class="dt">height =</span> <span class="fl">0.05</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<ul>
<li>Use <code>geom_smooth()</code> to add the logistic regression line to <code>data_space</code> by specifying the <code>method</code> and <code>method.args</code> arguments to fit a logistic <code>glm</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># add logistic curve</span>
data_space <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;glm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">method.args =</span> <span class="kw">list</span>(<span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>))</code></pre></div>
<p><img src="MultLogSC_files/figure-html/unnamed-chunk-48-1.png" width="384" style="display: block; margin: auto;" /></p>
<hr />
</div>
</div>
<div id="using-bins" class="section level2">
<h2><span class="header-section-number">5.5</span> Using bins</h2>
<p>One of the difficulties in working with a binary response variable is understanding how it âchanges.â The response itself (<span class="math inline">\(y\)</span>) is either 0 or 1, while the fitted values (<span class="math inline">\(\hat{y}\)</span>)âwhich are interpreted as probabilitiesâare between 0 and 1. But if every medical school applicant is either admitted or not, what does it mean to talk about the probability of being accepted?</p>
<p>What weâd like is a larger sample of students, so that for each GPA value (e.g.Â 3.54) we had many observations (say <span class="math inline">\(n\)</span>), and we could then take the average of those <span class="math inline">\(n\)</span> observations to arrive at the estimated probability of acceptance. Unfortunately, since the explanatory variable is continuous, this is hopelessâit would take an infinite amount of data to make these estimates robust.</p>
<p>Instead, what we can do is put the observations into bins based on their GPA value. Within each bin, we can compute the proportion of accepted students, and we can visualize our model as a smooth logistic curve through those binned values.</p>
<p>We have created a <code>data.frame</code> called <code>MedGPA_binned</code> that aggregates the original data into separate bins for each <strong>1/6</strong> of GPA. It also contains the fitted values from the logistic regression model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gpa_bins &lt;-<span class="st"> </span><span class="kw">quantile</span>(MedGPA<span class="op">$</span>GPA, <span class="dt">probs =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">6</span>))
gpa_bins</code></pre></div>
<pre><code>       0% 16.66667% 33.33333%       50% 66.66667% 83.33333%      100% 
     2.72      3.30      3.44      3.58      3.70      3.87      3.97 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MedGPA<span class="op">$</span>bins &lt;-<span class="st"> </span><span class="kw">cut</span>(MedGPA<span class="op">$</span>GPA, <span class="dt">breaks =</span> gpa_bins, <span class="dt">include.lowest =</span> <span class="ot">TRUE</span>)
<span class="kw">head</span>(MedGPA)</code></pre></div>
<pre><code>  Accept Acceptance Sex BCPM  GPA VR PS WS BS MCAT Apps       bins
1      D          0   F 3.59 3.62 11  9  9  9   38    5 (3.58,3.7]
2      A          1   M 3.75 3.84 12 13  8 12   45    3 (3.7,3.87]
3      A          1   F 3.24 3.23  9 10  5  9   33   19 [2.72,3.3]
4      A          1   F 3.74 3.69 12 11  7 10   40    5 (3.58,3.7]
5      A          1   F 3.53 3.38  9 11  4 11   35   11 (3.3,3.44]
6      A          1   M 3.59 3.72 10  9  7 10   36    5 (3.7,3.87]</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MedGPA_binned &lt;-<span class="st"> </span>MedGPA <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(bins) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_GPA =</span> <span class="kw">mean</span>(GPA), <span class="dt">acceptance_rate =</span> <span class="kw">mean</span>(Acceptance))
MedGPA_binned</code></pre></div>
<pre><code># A tibble: 6 x 3
  bins        mean_GPA acceptance_rate
  &lt;fct&gt;          &lt;dbl&gt;           &lt;dbl&gt;
1 [2.72,3.3]      3.11           0.2  
2 (3.3,3.44]      3.39           0.2  
3 (3.44,3.58]     3.54           0.75 
4 (3.58,3.7]      3.65           0.333
5 (3.7,3.87]      3.79           0.889
6 (3.87,3.97]     3.91           1    </code></pre>
<p>Here we are plotting <span class="math inline">\(y\)</span> as a function of <span class="math inline">\(x\)</span>, where that function is</p>
<span class="math display">\[\begin{equation}
\hat{p}(X) = \widehat{\text{Pr}}(Y=1|X) = \frac{\exp(\hat{\beta}_0 + \hat{\beta}_1 x)}{1 + \exp(\hat{\beta}_0 + \hat{\beta}_1 x)}
\end{equation}\]</span>
<p>Note that the left hand side is the expected probability <span class="math inline">\(y\)</span> of being accepted to medical school.</p>
<hr />
<div id="exercise-16" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Create a scatterplot called <code>data_space</code> for <code>acceptance_rate</code> as a function of <code>mean_GPA</code> using the binned data in <code>MedGPA_binned</code>. Use <code>geom_line()</code> to connect the points.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># binned points and line</span>
data_space &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> MedGPA_binned, <span class="kw">aes</span>(<span class="dt">x =</span> mean_GPA, <span class="dt">y =</span> acceptance_rate)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()
data_space</code></pre></div>
<p><img src="MultLogSC_files/figure-html/unnamed-chunk-52-1.png" width="384" style="display: block; margin: auto;" /></p>
<ul>
<li>Augment the model <code>mod</code>. Create predictions on the scale of the response variable by using the <code>type.predict</code> argument.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># augmented model</span>
MedGPA_plus &lt;-<span class="st"> </span>mod <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">augment</span>(<span class="dt">type.predict =</span> <span class="st">&quot;response&quot;</span>)</code></pre></div>
<ul>
<li>Use <code>geom_line()</code> to illustrate the model through the fitted values.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># logistic model on probability scale</span>
data_space <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> MedGPA_plus, <span class="kw">aes</span>(<span class="dt">x =</span> GPA, <span class="dt">y =</span> .fitted), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="MultLogSC_files/figure-html/unnamed-chunk-54-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>The logistic predictions seem to follow the binned values pretty well.</p>
<hr />
</div>
</div>
<div id="odds-scale" class="section level2">
<h2><span class="header-section-number">5.6</span> Odds scale</h2>
<p>For most people, the idea that we could estimate the probability of being admitted to medical school based on undergraduate GPA is fairly intuitive. However, thinking about how the probability changes as a function of GPA is complicated by the non-linear logistic curve. By translating the response from the probability scale to the <a href="https://en.wikipedia.org/wiki/Odds">odds</a> scale, we make the right hand side of our equation easier to understand.</p>
<p>If the probability of getting accepted is <span class="math inline">\(y\)</span>, then the odds are <span class="math inline">\(y/(1-y)\)</span>. Expressions of probabilities in terms of odds are common in many situations, perhaps most notably gambling.</p>
<p>Here we are plotting <span class="math inline">\(y\)</span>/(<span class="math inline">\(1-y\)</span>)as a function of <span class="math inline">\(x\)</span>, where that function is</p>
<span class="math display">\[\begin{equation}
\text{odds}(\hat{y})=\frac{\hat{y}}{1 - \hat{y}}=\exp(\hat{\beta}_0 + \hat{\beta}_1 \cdot x)
\end{equation}\]</span>
<p>Note that the left hand side is the expected odds of being accepted to medical school. The right hand side is now a familiar exponential function of <span class="math inline">\(x\)</span>.</p>
<p>The <code>MedGPA_binned</code> data frame contains the data for each GPA bin, while the <code>MedGPA_plus</code> data frame records the original observations after being <code>augment()</code>-ed by <code>mod</code>.</p>
<hr />
<div id="exercise-17" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Add a variable called <code>odds</code> to <code>MedGPA_binned</code> that records the odds of being accepted to medical school for each bin.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute odds for bins</span>
MedGPA_binned &lt;-<span class="st"> </span>MedGPA_binned <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">odds =</span> acceptance_rate <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>acceptance_rate))</code></pre></div>
<ul>
<li>Create a scatterplot called <code>data_space</code> for <code>odds</code> as a function of <code>mean_GPA</code> using the binned data in <code>MedGPA_binned</code>. Connect the points with <code>geom_line()</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot binned odds</span>
data_space &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> MedGPA_binned, 
                     <span class="kw">aes</span>(<span class="dt">x =</span> mean_GPA, <span class="dt">y =</span> odds)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()
data_space</code></pre></div>
<p><img src="MultLogSC_files/figure-html/unnamed-chunk-56-1.png" width="384" style="display: block; margin: auto;" /></p>
<ul>
<li>Add a variable called <code>odds_hat</code> to <code>MedGPA_plus</code> that records the predicted odds of being accepted for each observation.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute odds for observations</span>
MedGPA_plus &lt;-<span class="st"> </span>MedGPA_plus <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">odds_hat =</span> .fitted <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>.fitted))</code></pre></div>
<ul>
<li>Use <code>geom_line()</code> to illustrate the model through the fitted values. Note that you should be plotting the <span class="math inline">\(\hat{odds}\)</span>âs.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># logistic model on odds scale</span>
data_space <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> MedGPA_plus, <span class="kw">aes</span>(<span class="dt">x =</span> GPA, <span class="dt">y =</span> odds_hat), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="MultLogSC_files/figure-html/unnamed-chunk-58-1.png" width="384" style="display: block; margin: auto;" /></p>
<hr />
</div>
</div>
<div id="log-odds-scale" class="section level2">
<h2><span class="header-section-number">5.7</span> Log-odds scale</h2>
<p>Previously, we considered two formulations of logistic regression models:</p>
<ul>
<li><p>on the probability scale, the units are easy to interpret, but the function is non-linear, which makes it hard to understand</p></li>
<li><p>on the odds scale, the units are harder (but not impossible) to interpret, and the function is exponential, which makes it harder (but not impossible) to interpret</p></li>
</ul>
<p>Weâll now add a third formulation:</p>
<ul>
<li>on the log-odds scale, the units are nearly impossible to interpret, but the function is linear, which makes it easy to understand As you can see, none of these three is uniformly superior. Most people tend to interpret the fitted values on the probability scale and the function on the log-odds scale. The interpretation of the coefficients is most commonly done on the odds scale. Recall that we interpreted our slope coefficient <span class="math inline">\(\beta_1\)</span> in linear regression as the expected change in <span class="math inline">\(y\)</span> given a one unit change in <span class="math inline">\(x\)</span>. On the probability scale, the function is non-linear and so this approach wonât work. On the log-odds, the function is linear, but the units are not interpretable (what does the log of the odds mean??). However, on the odds scale, a one unit change in <span class="math inline">\(x\)</span> leads to the odds being multiplied by a factor of <span class="math inline">\(\hat{\beta_1}\)</span>. To see why, we form the odds ratio:</li>
</ul>
<span class="math display">\[\begin{equation}
\text{OR}=\frac{\text{odds}(\hat{y}|x + 1)}{\text{odds}(\hat{y}|x)} = \exp \hat{\beta}_1
\end{equation}\]</span>
<p>Thus, the exponentiated coefficient <span class="math inline">\(\beta_1\)</span> tells us how the expected odds change for a one unit increase in the explanatory variable. It is tempting to interpret this as a change in the expected probability, but this is wrong and can lead to nonsensical predictions (e.g.Â expected probabilities greater than 1).</p>
<hr />
<div id="exercise-18" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Add a variable called <code>log_odds</code> to <code>MedGPA_binned</code> that records the odds of being accepted for each bin. Recall that <span class="math inline">\(odds(p) = p/(1-p)\)</span>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute log odds for bins</span>
MedGPA_binned &lt;-<span class="st"> </span>MedGPA_binned <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">mutate</span>(<span class="dt">log_odds =</span> <span class="kw">log</span>(acceptance_rate <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>acceptance_rate)))</code></pre></div>
<ul>
<li>Create a scatterplot called <code>data_space</code> for <code>log_odds</code> as a function of <code>mean_GPA</code> using the binned data in <code>MedGPA_binned</code>. Use <code>geom_line</code> to connect the points.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot binned log odds</span>
data_space &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> MedGPA_binned, 
<span class="kw">aes</span>(<span class="dt">y =</span> log_odds, <span class="dt">x =</span> mean_GPA)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">theme_bw</span>()
data_space</code></pre></div>
<p><img src="MultLogSC_files/figure-html/unnamed-chunk-60-1.png" width="384" style="display: block; margin: auto;" /></p>
<ul>
<li>Add a variable called <code>log_odds_hat</code> to <code>MedGPA_plus</code> that records the predicted odds of being accepted for each observation.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute log odds for observations</span>
MedGPA_plus &lt;-<span class="st"> </span>MedGPA_plus <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">log_odds_hat =</span> <span class="kw">log</span>(.fitted <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>.fitted)))</code></pre></div>
<ul>
<li>Use <code>geom_line()</code> to illustrate the model through the fitted values. Note that you should be plotting the <span class="math inline">\(\widehat{\text{odds}}\)</span>âs.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># logistic model on log odds scale</span>
data_space <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> MedGPA_plus, <span class="kw">aes</span>(<span class="dt">x =</span> GPA, <span class="dt">y =</span> log_odds_hat), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="MultLogSC_files/figure-html/unnamed-chunk-62-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>When youâre on the log-odds scale, your model is a simple linear function.</p>
<hr />
</div>
<div id="interpretation-of-logistic-regression" class="section level3 unnumbered">
<h3>Interpretation of logistic regression</h3>
<p>The fitted coefficient <span class="math inline">\(\hat\beta_1\)</span> from the medical school logistic regression model is 5.45. The exponential of this is 233.73.</p>
<p>Donaldâs GPA is 2.9, and thus the model predicts that the probability of him getting into medical school is 3.26%. The odds of Donald getting into medical school are 0.0337, orâphrased in gambling termsâ29.6:1. If Donald hacks the schoolâs registrar and changes his GPA to 3.9, then which of the following statements is <strong>FALSE</strong>:</p>
<ul>
<li><p>His expected odds of getting into medical school improve to 7.8833 (or about 9:8).</p></li>
<li><p>His expected probability of getting into medical school improves to 88.7%.</p></li>
<li><p>His expected log-odds of getting into medical school improve by 5.45.</p></li>
<li><p><strong>His expected probability of getting into medical school improves to 7.9%.</strong> This is a FALSE statement.</p></li>
</ul>
<hr />
</div>
</div>
<div id="making-probabilistic-predictions" class="section level2">
<h2><span class="header-section-number">5.8</span> Making probabilistic predictions</h2>
<p>Just as we did with linear regression, we can use our logistic regression model to make predictions about new observations. In this exercise, we will use the <code>newdata</code> argument to the <code>augment()</code> function from the <code>broom</code> package to make predictions about students who were not in our original data set. These predictions are sometimes called <em>out-of-sample</em>.</p>
<p>Following our previous discussion about scales, with logistic regression it is important that we specify on which scale we want the predicted values. Although the default is <code>link</code> â which uses the log-odds scale â we want our predictions on the probability scale, which is the scale of the <code>response</code> variable. The <code>type.predict</code> argument to <code>augment()</code> controls this behavior.</p>
<hr />
<div id="exercise-19" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Create a new data frame which has one variable called <code>GPA</code> and one row, with the value 3.51.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create new data frame</span>
new_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">GPA =</span> <span class="fl">3.51</span>)</code></pre></div>
<ul>
<li>Use <code>augment()</code> to find the expected probability of admission to medical school for a student with a GPA of 3.51.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># make predictions</span>
<span class="kw">augment</span>(mod, <span class="dt">newdata =</span> new_data, <span class="dt">type.predict =</span> <span class="st">&quot;response&quot;</span>)</code></pre></div>
<pre><code># A tibble: 1 x 3
    GPA .fitted .se.fit
  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
1  3.51   0.484  0.0834</code></pre>
<p>By framing your prediction as a probability you can show how likely it is that this student will get admitted to medical school.</p>
<hr />
</div>
</div>
<div id="making-binary-predictions" class="section level2">
<h2><span class="header-section-number">5.9</span> Making binary predictions</h2>
<p>Naturally, we want to know how well our model works. Did it predict acceptance for the students who were actually accepted to medical school? Did it predict rejections for the student who were not admitted? These types of predictions are called in-sample. One common way to evaluate models with a binary response is with a <a href="https://en.wikipedia.org/wiki/Confusion_matrix">confusion matrix</a>. [Yes, that is actually what it is called!]</p>
<p>However, note that while our response variable is binary, our fitted values are probabilities. Thus, we have to round them somehow into binary predictions. While the probabilities convey more information, we might ultimately have to make a decision, and so this rounding is common in practice. There are many different ways to round, but for simplicity we will predict admission if the fitted probability is greater than 0.5, and rejection otherwise.</p>
<p>First, weâll use <code>augment()</code> to make the predictions, and then <code>mutate()</code> and <code>round()</code> to convert these probabilities into binary decisions. Then we will form the confusion matrix using the <code>table()</code> function. <code>table()</code> will compute a 2-way table when given a data frame with two categorical variables, so we will first use <code>select()</code> to grab only those variables.</p>
<p>You will find that this model made only 15 mistakes on these 55 observations, so it is nearly 73% accurate.</p>
<hr />
<div id="exercise-20" class="section level3 unnumbered">
<h3>Exercise</h3>
<p>The model object <code>mod</code> is already in your workspace.</p>
<ul>
<li>Create a data frame with the actual observations, and their fitted probabilities, and add a new column with the binary decision by rounding the fitted probabilities.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># data frame with binary predictions</span>
tidy_mod &lt;-<span class="st"> </span><span class="kw">augment</span>(mod, <span class="dt">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Acceptance_hat =</span> <span class="kw">round</span>(.fitted)) </code></pre></div>
<ul>
<li>Compute the confusion matrix between the actual and predicted acceptance.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># confusion matrix</span>
tidy_mod <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(Acceptance, Acceptance_hat) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">table</span>()</code></pre></div>
<pre><code>          Acceptance_hat
Acceptance  0  1
         0 16  9
         1  6 24</code></pre>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multiple-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="case-study-italian-restaurant-in-nyc.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["MultLogSC.pdf", "MultLogSC.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
